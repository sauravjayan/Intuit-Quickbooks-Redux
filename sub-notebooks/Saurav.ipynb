{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intuit Quickbooks Upgrade\n",
    "\n",
    "* Team-lead GitLab userid:\n",
    "* Group name:\n",
    "* Team member names:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Please complete this python notebook with your group by answering the questions in `intuit-redux.pdf`. Create a Notebook and HTML file with all your results and comments and push both the Notebook and HTML file to GitLab when your team is done. All results MUST be reproducible (i.e., the TA and I must be able to recreate the HTML file from the Jupyter Notebook without changes or errors). This means that you should NOT use any python-packages that are not part of the rsm-msba-spark docker container.\n",
    "\n",
    "This is the second group assignment for MGTA 455 and you will be using Git and GitLab. If two people edit the same file at the same time you could get what is called a \"merge conflict\". This is not something serious but you should realize that Git will not decide for you who's change to accept so the team-lead will have to determine the edits to use. To avoid merge conflicts, **always** \"pull\" changes to the repo before you start working on any files. Then, when you are done, save and commit your changes, and then push them to GitLab. Make \"pull first\" a habit!\n",
    "\n",
    "If multiple people are going to work on the assignment at the same time I recommend you work in different notebooks. You can then `%run ...`  these \"sub\" notebooks from the main assignment file. You can seen an example of this in action below for the `model1.ipynb` notebook\n",
    "\n",
    "Some group work-flow tips:\n",
    "\n",
    "* Pull, edit, save, stage, commit, and push\n",
    "* Schedule who does what and when\n",
    "* Try to avoid working simultaneously on the same file \n",
    "* If you are going to work simultaneously, do it in different notebooks, e.g., \n",
    "    - model1.ipynb, model2.ipynb, model3.ipynb\n",
    "* Use the `%run ... ` command to bring different pieces of code together into the main jupyter notebook\n",
    "* Put python functions in modules that you can import from your notebooks. See the example below for the `example` function defined in `utils/functions.py`\n",
    "\n",
    "A graphical depiction of the group work-flow is shown below:\n",
    "\n",
    "![](images/git-group-workflow-wbg.png)\n",
    "\n",
    "Tutorial videos about using Git, GitLab, and GitGadget for group assignments:\n",
    "\n",
    "* Setup the MSBA server to use Git and GitLab: https://youtu.be/zJHwodmjatY\n",
    "* Dealing with Merge Conflicts: https://youtu.be/qFnyb8_rgTI\n",
    "* Group assignment practice: https://youtu.be/4Ty_94gIWeA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyrsm as rsm\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn import preprocessing\n",
    "from statsmodels.genmod.families import Binomial\n",
    "from statsmodels.genmod.families.links import logit\n",
    "import xgboost as xgb\n",
    "from sklearn import metrics\n",
    "from pyrsm import profit_max, confusion, profit_plot, gains_plot, lift_plot, ROME_plot\n",
    "from sklearn.model_selection import RandomizedSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " mpl.rcParams[\"figure.dpi\"] = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## loading the data - this dataset must NOT be changed\n",
    "intuit75k = pd.read_pickle(\"../data/intuit75k.pkl\")\n",
    "intuit75k[\"res1_yes\"] = (intuit75k[\"res1\"] == \"Yes\").astype(int)\n",
    "intuit75k.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show dataset description\n",
    "rsm.describe(intuit75k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intuit75k.zip_bins = intuit75k.zip_bins.astype(object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intuit75k = intuit75k.join(pd.get_dummies(intuit75k.sex), how='inner')\n",
    "intuit75k = intuit75k.join(pd.get_dummies(intuit75k.zip_bins), how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intuit75k.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intuit_train = intuit75k.query('training == 1').reset_index()\n",
    "intuit_val = intuit75k.query('training == 0').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = intuit_train.drop(columns=['id','zip', 'zip_bins','res1','res1_yes','training','sex','index'])\n",
    "y_train = intuit_train[['res1_yes']]\n",
    "X_test = intuit_val.drop(columns=['id','zip', 'zip_bins','res1','res1_yes','training','sex','index'])\n",
    "y_test = intuit_val[['res1_yes']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_clf = xgb.XGBClassifier(objective='binary:logistic', n_estimators=1000, seed=123, max_depth=2, n_jobs=6, use_label_encoder=False,reg_lambda=3, learning_rate=0.3)\n",
    "xgb_clf.fit(X_train, y_train.values.ravel(), early_stopping_rounds=10, eval_metric=\"auc\", verbose=True, eval_set=[(X_test, y_test.values.ravel())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction probabilities on the test set\n",
    "pred = xgb_clf.predict_proba(X_test)\n",
    "probs = pd.Series([p[1] for p in pred])\n",
    "\n",
    "# Prediction probabilities on the train set\n",
    "pred_train = xgb_clf.predict_proba(X_train)\n",
    "probs_train = pd.Series([p[1] for p in pred_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = metrics.roc_curve(y_test.res1_yes, pred[:,1])\n",
    "print(f'Test data auc is {metrics.auc(fpr,tpr)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = metrics.roc_curve(y_train.res1_yes, pred_train[:,1])\n",
    "print(f'Train data auc is {metrics.auc(fpr,tpr)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breakeven = 1.41/30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_prof = pd.Series((probs)) \n",
    "pred_prof.name = 'predictions_xgb_1_test'\n",
    "\n",
    "pred_prof_train = pd.Series((probs_train))\n",
    "pred_prof_train.name = 'predictions_xgb_1_train'\n",
    "\n",
    "df_test = y_test.join(pred_prof, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = profit_max(df_test,'res1_yes',1,'predictions_xgb_1_test',1.41,30)\n",
    "\n",
    "print(f'The profit for {xgb_clf} on the test data is ${round(p,3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP, FP, TN, FN, contact = confusion(df_test,'res1_yes',1,'predictions_xgb_1_test',1.41,30)\n",
    "\n",
    "print(f'TP: {TP}')\n",
    "print(f'TN: {TN}')\n",
    "print(f'FP: {FP}')\n",
    "print(f'FN: {FN}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['target_xgb'] = (df_test.predictions_xgb_1_test > breakeven).astype(int)\n",
    "\n",
    "total_biz = 801821\n",
    "already_resp = 38487\n",
    "population = total_biz - already_resp\n",
    "response_rate_xgb = np.mean(df_test[df_test.target_xgb == 1]['res1_yes'])\n",
    "targets = population * contact\n",
    "responses = targets * (response_rate_xgb/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = targets * 1.41\n",
    "rev = responses * 60\n",
    "profit = rev - cost\n",
    "print(f'The projected profit for the those people who did not respond to wave 1 of mailing but will be mailed a second time is $ {round(profit,2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams[\"figure.dpi\"] = 500\n",
    "xgb.plot_tree(xgb_clf, rankdir='LR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = xgb.XGBClassifier(objective='binary:logistic',seed=123, use_label_encoder=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_param_grid = {\n",
    "    'xgb_clf__learning_rate': np.arange(0.05, 0.4, 0.05),\n",
    "    'xgb_clf__max_depth': np.arange(1, 6, 1),\n",
    "    'xgb_clf__n_estimators': np.arange(1000, 2000, 100)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "def profit_scoring(y_true, y_pred):\n",
    "    profit = rsm.profit(pd.Series(y_true), pd.Series(y_pred), 1, 1.41, 30)\n",
    "    return profit\n",
    "\n",
    "profit_score = make_scorer(profit_scoring, greater_is_better = True, needs_proba=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomized_roc_auc = RandomizedSearchCV(scoring=profit_scoring,verbose=1, estimator=clf, param_distributions=gbm_param_grid, n_jobs=6)\n",
    "randomized_roc_auc.fit(X_train,y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
