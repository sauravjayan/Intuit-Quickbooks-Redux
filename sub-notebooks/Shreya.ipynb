{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intuit Quickbooks Upgrade\n",
    "\n",
    "* Team-lead GitLab userid:\n",
    "* Group name:\n",
    "* Team member names:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Please complete this python notebook with your group by answering the questions in `intuit-redux.pdf`. Create a Notebook and HTML file with all your results and comments and push both the Notebook and HTML file to GitLab when your team is done. All results MUST be reproducible (i.e., the TA and I must be able to recreate the HTML file from the Jupyter Notebook without changes or errors). This means that you should NOT use any python-packages that are not part of the rsm-msba-spark docker container.\n",
    "\n",
    "This is the second group assignment for MGTA 455 and you will be using Git and GitLab. If two people edit the same file at the same time you could get what is called a \"merge conflict\". This is not something serious but you should realize that Git will not decide for you who's change to accept so the team-lead will have to determine the edits to use. To avoid merge conflicts, **always** \"pull\" changes to the repo before you start working on any files. Then, when you are done, save and commit your changes, and then push them to GitLab. Make \"pull first\" a habit!\n",
    "\n",
    "If multiple people are going to work on the assignment at the same time I recommend you work in different notebooks. You can then `%run ...`  these \"sub\" notebooks from the main assignment file. You can seen an example of this in action below for the `model1.ipynb` notebook\n",
    "\n",
    "Some group work-flow tips:\n",
    "\n",
    "* Pull, edit, save, stage, commit, and push\n",
    "* Schedule who does what and when\n",
    "* Try to avoid working simultaneously on the same file \n",
    "* If you are going to work simultaneously, do it in different notebooks, e.g., \n",
    "    - model1.ipynb, model2.ipynb, model3.ipynb\n",
    "* Use the `%run ... ` command to bring different pieces of code together into the main jupyter notebook\n",
    "* Put python functions in modules that you can import from your notebooks. See the example below for the `example` function defined in `utils/functions.py`\n",
    "\n",
    "A graphical depiction of the group work-flow is shown below:\n",
    "\n",
    "![](images/git-group-workflow-wbg.png)\n",
    "\n",
    "Tutorial videos about using Git, GitLab, and GitGadget for group assignments:\n",
    "\n",
    "* Setup the MSBA server to use Git and GitLab: https://youtu.be/zJHwodmjatY\n",
    "* Dealing with Merge Conflicts: https://youtu.be/qFnyb8_rgTI\n",
    "* Group assignment practice: https://youtu.be/4Ty_94gIWeA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyrsm as rsm\n",
    "from sklearn import metrics\n",
    "from pyrsm import profit_max, confusion, profit_plot, gains_plot, lift_plot, ROME_plot\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import load_model\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## loading the data - this dataset must NOT be changed\n",
    "intuit75k = pd.read_pickle(\"../data/intuit75k.pkl\")\n",
    "intuit75k[\"res1_yes\"] = (intuit75k[\"res1\"] == \"Yes\").astype(int)\n",
    "intuit75k.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show dataset description\n",
    "rsm.describe(intuit75k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardization\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "sf = scaler.fit(intuit75k.query('training==1')[['numords','dollars','last','sincepurch']])\n",
    "intuit75k[['numords','dollars','last','sincepurch']] = sf.transform(intuit75k[['numords','dollars','last','sincepurch']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "def profit_scoring(y_true, y_pred):\n",
    "    profit = rsm.profit(pd.Series(y_true), pd.Series(y_pred), 1, 1.41, 60)\n",
    "    return profit\n",
    "\n",
    "profit_score = make_scorer(profit_scoring, greater_is_better = True, needs_proba=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intuit75k.zip_bins = intuit75k.zip_bins.astype(object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#One-hot encoding of categorical variables\n",
    "intuit75k = intuit75k.join(pd.get_dummies(intuit75k.zip_bins), how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting zips 00801 and 00804\n",
    "intuit75k = intuit75k.assign(\n",
    "\n",
    "    zip801 = (intuit75k['zip'] == '00801').astype(int),\n",
    "    zip804 = (intuit75k['zip'] == '00804').astype(int)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting train and test dataset\n",
    "intuit_train = intuit75k.query('training == 1').reset_index()\n",
    "intuit_test = intuit75k.query('training == 0').reset_index()\n",
    "intuit_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating X and Y datasets \n",
    "X_train = intuit_train.drop(columns=['id','zip', 'zip_bins','res1','res1_yes','training','sex','index','bizflag'])\n",
    "y_train = intuit_train[['res1_yes']]\n",
    "X_test = intuit_test.drop(columns=['id','zip', 'zip_bins','res1','res1_yes','training','sex','index','bizflag'])\n",
    "y_test = intuit_test[['res1_yes']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of columns to define input shape of model\n",
    "ncols= X_test.shape[1]\n",
    "ncols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model creation\n",
    "model= Sequential()\n",
    "model.add(Dense(50, activation='relu', input_shape=(ncols,)))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model compilation and fit\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, to_categorical(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predictions from model\n",
    "predictions= model.predict(X_test)\n",
    "prob_true = pd.Series([p[1] for p in predictions])\n",
    "prob_true.name = 'predictions_test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prob to respond \n",
    "df_test = y_test.join(prob_true, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating breakeven response rate\n",
    "breakeven = 1.41/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating confusion matrix\n",
    "TP, FP, TN, FN, contact = confusion(df_test,'res1_yes',1,'predictions_test',1.41,60)\n",
    "\n",
    "print(f'TP: {TP}')\n",
    "print(f'TN: {TN}')\n",
    "print(f'FP: {FP}')\n",
    "print(f'FN: {FN}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating profit on test dataset \n",
    "p = profit_max(df_test,'res1_yes',1,'predictions_test',1.41,30)\n",
    "\n",
    "print(f'The profit on the test data is ${round(p,3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use scikit-learn to grid search the batch size and epochs\n",
    "\n",
    "# Function to create model, required for KerasClassifier\n",
    "def create_model(neurons=1, activation=activation):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, activation=activation))\n",
    "    model.add(Dense(neurons, activation=activation))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
    "    return model\n",
    "# fix random seed for reproducibility\n",
    "seed = 1234\n",
    "np.random.seed(seed)\n",
    "\n",
    "# create model\n",
    "model = KerasClassifier(build_fn=create_model, epochs=100, batch_size=10, verbose=0)\n",
    "# define the grid search parameters\n",
    "activation= ['linear','relu','softmax','tanh','sigmoid']\n",
    "neurons= [1, 5, 10, 15, 20, 25, 30, 50, 100]\n",
    "param_grid = dict(neurons=neurons, activation=activation)\n",
    "grid = RandomizedSearchCV(estimator=model, param_grid=param_grid, n_jobs=4, cv=3, n_iter=20)\n",
    "grid_result = grid.fit(X_train, to_categorical(y_train))\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
